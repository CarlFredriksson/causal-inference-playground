{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "NUM_DATA_POINTS = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "I just finished studying Brady Neal's [Introduction to Causal Inference](https://www.bradyneal.com/causal-inference-course) course. It was a great introduction to the topic for me, and the author was kind enough to release both the lectures and the associated course book for free (at the time of writing this there were a few chapters not yet published). The main goal of this article is to get my hands dirty and solidify some of the things I learned - even better if it turns out helping someone else as well.\n",
    "\n",
    "Let's start off with some semantics. The following figure from the course book illustrates a general procedure of causal inference - the flow from a causal estimand + causal model to a statistical estimand, and from a statistical estimand + data to an estimate. Here is a short summary of what the different terms mean:\n",
    "\n",
    "* Causal Estimand\n",
    "  * The causal expression we are interested in evaluating.\n",
    "  * Contains either one or more potential outcomes, e.g. $Y(t)$, or one ore more do-operators, e.g. $P(Y|do(T=t))$.\n",
    "  * In this article I will primarily consider the causal estimand *average treatment effect* (ATE): $E[Y(1) - Y(0)] = E[Y|do(T=1)] - E[Y|do(T=0)]$\n",
    "* Statistical Estimand:\n",
    "  * Identification etc\n",
    "* Estimate:\n",
    "  * Estimation\n",
    "* Causal Model:\n",
    "  * Used to identify the causal estimand\n",
    "  * DAG vs SCM\n",
    "* Data:\n",
    "  * Used in estimation of statistical estimand to get estimate\n",
    "\n",
    "![figures/identification_estimation_flowchart.png](figures/identification_estimation_flowchart.png)\n",
    "\n",
    "Conditional Outcome Modeling (COM) estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Model\n",
    "\n",
    "## Graphical Model (DAG)\n",
    "\n",
    "![figures/dag_1.png](figures/dag_1.png)\n",
    "\n",
    "## Structural Causal Model (SCM)\n",
    "\n",
    "## Data generating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_w():\n",
    "    u_w = np.random.choice([0, 1])\n",
    "    return u_w\n",
    "\n",
    "def f_t(w):\n",
    "    u_t = np.random.normal()\n",
    "    intermediate = 0.5 * w + u_t\n",
    "    return 1 if intermediate > 0 else 0\n",
    "\n",
    "def f_y(w, t):\n",
    "    u_y = np.random.normal()\n",
    "    return 0.8 * w + 1.2 * t + u_y\n",
    "\n",
    "W = np.array([f_w() for _ in range(NUM_DATA_POINTS)])\n",
    "T = np.array([f_t(w) for w in W])\n",
    "Y = np.array([f_y(w, t) for w, t in zip(W, T)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification\n",
    "\n",
    "Backdoor criterion\n",
    "\n",
    "Backdoor adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation\n",
    "\n",
    "Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE estimate: 1.2012474981998513\n"
     ]
    }
   ],
   "source": [
    "WT = np.array([W, T]).T\n",
    "WT_1 = np.array([W, np.ones(len(W))]).T\n",
    "WT_0 = np.array([W, np.zeros(len(W))]).T\n",
    "model = LinearRegression()\n",
    "model.fit(WT, Y)\n",
    "ate_estimate = np.mean(model.predict(WT_1) - model.predict(WT_0))\n",
    "print(\"ATE estimate:\", ate_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE estimate: 1.2012474981998507\n"
     ]
    }
   ],
   "source": [
    "print(\"ATE estimate:\", model.coef_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colliders\n",
    "\n",
    "![figures/dag_2.png](figures/dag_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_w():\n",
    "    u_w = np.random.choice([0, 1])\n",
    "    return u_w\n",
    "\n",
    "def f_t(w):\n",
    "    u_t = np.random.normal()\n",
    "    intermediate = 0.5 * w + u_t\n",
    "    return 1 if intermediate > 0 else 0\n",
    "\n",
    "def f_y(w, t):\n",
    "    u_y = np.random.normal()\n",
    "    return 0.8 * w + 1.2 * t + u_y\n",
    "\n",
    "def f_z(t, y):\n",
    "    u_z = np.random.normal()\n",
    "    intermediate = 1.5 * t + y - 2 + u_z\n",
    "    return 1 if intermediate > 0 else 0\n",
    "\n",
    "W = np.array([f_w() for _ in range(NUM_DATA_POINTS)])\n",
    "T = np.array([f_t(w) for w in W])\n",
    "Y = np.array([f_y(w, t) for w, t in zip(W, T)])\n",
    "Z = np.array([f_z(t, y) for t, y in zip(T, Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE estimate: 0.40757848747942743\n"
     ]
    }
   ],
   "source": [
    "WZT = np.array([W, Z, T]).T\n",
    "WZT_1 = np.array([W, Z, np.ones(len(W))]).T\n",
    "WZT_0 = np.array([W, Z, np.zeros(len(W))]).T\n",
    "model = LinearRegression()\n",
    "model.fit(WZT, Y)\n",
    "ate_estimate = np.mean(model.predict(WZT_1) - model.predict(WZT_0))\n",
    "print(\"ATE estimate:\", ate_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE estimate: 1.196696813274864\n"
     ]
    }
   ],
   "source": [
    "WT = np.array([W, T]).T\n",
    "WT_1 = np.array([W, np.ones(len(W))]).T\n",
    "WT_0 = np.array([W, np.zeros(len(W))]).T\n",
    "model = LinearRegression()\n",
    "model.fit(WT, Y)\n",
    "ate_estimate = np.mean(model.predict(WT_1) - model.predict(WT_0))\n",
    "print(\"ATE estimate:\", ate_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unobserved confounding\n",
    "\n",
    "![figures/dag_3.png](figures/dag_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_w():\n",
    "    u_w = np.random.choice([0, 1])\n",
    "    return u_w\n",
    "\n",
    "def f_u():\n",
    "    u_u = np.random.normal()\n",
    "    return u_u\n",
    "\n",
    "def f_t(w, u):\n",
    "    u_t = np.random.normal()\n",
    "    intermediate = 0.5 * w + 0.8 * u + u_t\n",
    "    return 1 if intermediate > 0 else 0\n",
    "\n",
    "def f_y(w, u, t):\n",
    "    u_y = np.random.normal()\n",
    "    return 0.8 * w - 2 * u + 1.2 * t + u_y\n",
    "\n",
    "W = np.array([f_w() for _ in range(NUM_DATA_POINTS)])\n",
    "U = np.array([f_u() for _ in range(NUM_DATA_POINTS)])\n",
    "T = np.array([f_t(w, u) for w, u in zip(W, U)])\n",
    "Y = np.array([f_y(w, u, t) for w, u, t in zip(W, U, T)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE estimate: -0.8108111630460578\n"
     ]
    }
   ],
   "source": [
    "WT = np.array([W, T]).T\n",
    "WT_1 = np.array([W, np.ones(len(W))]).T\n",
    "WT_0 = np.array([W, np.zeros(len(W))]).T\n",
    "model = LinearRegression()\n",
    "model.fit(WT, Y)\n",
    "ate_estimate = np.mean(model.predict(WT_1) - model.predict(WT_0))\n",
    "print(\"ATE estimate:\", ate_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "TODO\n",
    "\n",
    "Just a small part of causal inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-inference-playground-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
