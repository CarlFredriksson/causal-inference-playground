{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "NUM_DATA_POINTS = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "I just finished studying Brady Neal's [Introduction to Causal Inference](https://www.bradyneal.com/causal-inference-course) course. It was a great introduction to the topic for me, and the author was kind enough to release both the lectures and the associated course book for free (at the time of writing this there were a few chapters not yet published). The main goal of this article is to get my hands dirty and solidify some of the things I learned - it would be a nice bonus if it turns out helping someone else as well!\n",
    "\n",
    "Let's start off with some semantics. The figure 4.1 from the course book illustrates a general procedure of causal inference - the flow from a causal estimand + causal model to a statistical estimand, and from a statistical estimand + data to an estimate. Here are some relevant terms, using the definitions from the [Introduction to Causal Inference](https://www.bradyneal.com/causal-inference-course)-book:\n",
    "\n",
    "* **Causal Estimand**\n",
    "  * The causal expression we are interested in evaluating. Can not be directly estimated from data.\n",
    "  * Contains one or more potential outcomes or $do$-operators, e.g. $\\mathbb{E}[Y(t)] = \\mathbb{E}[Y|do(T=t)]$.\n",
    "    * Both sides of the equality can be read as \"the expected value of the outcome variable $Y$, given that the population of interest receives treatment $T=t$\". The left side utilizes potential outcome notation and the right side $do$-operator notation.\n",
    "    * Note that \"receives treatment\" doesn't have to mean a designed intervention in this context, see [Does Obesity Shorten Life? Or is it the Soda? On Non-manipulable Causes (Pearl, 2018)](https://ftp.cs.ucla.edu/pub/stat_ser/r483-reprint.pdf) for more information.\n",
    "  * In this article I will primarily consider the specific causal estimand *average treatment effect* (ATE): $E[Y(1) - Y(0)] = E[Y|do(T=1)] - E[Y|do(T=0)]$. I will focus on the case where the treatment is binary, with $T=1$ denoting treatment and $T=0$ no treatment. However, most of the concepts I will cover easily extend to the continuous treatment case.\n",
    "* **Statistical Estimand**\n",
    "  * Unlike causal estimands, statistical estimands contain no potential outcomes or $do$-operators and can be estimated from data. Therefore a big part of causal inference is identification - the process of moving from a causal estimand to a statistical estimand.\n",
    "  * What statistical estimand is a proper identification of the causal estimand of interest depends on the causal model. Causal models are commonly visualized by a *directed acyclic graph* (DAG) and/or specified by a *structural casual model* (SCM).\n",
    "* **Estimate (noun)**\n",
    "  * An approximation of the estimand we want to estimate (verb) - a concrete value or distribution. The outcome of estimating a statistical estimand using data.\n",
    "  * An estimator is a function that maps from a dataset to an estimate of the (statistical) estimand we are considering.\n",
    "  * There are many ways to do estimation. In this article I will focus on *conditional outcome modeling* (COM). Other types of methods include, but are not limited to:\n",
    "    * Matching methods\n",
    "    * Inverse probability weighting\n",
    "    * Double machine learning\n",
    "    * Causal trees and forests\n",
    "\n",
    "![figures/identification_estimation_flowchart.png](figures/identification_estimation_flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Model\n",
    "\n",
    "When working with observational data and attempting to make causal inferences, thinking about the underlying causal model that generated the data is essential (in the experimental setting, when running well designed randomized controlled trials, it's less important due to the random selection into treatment and control groups that makes sure there is no confounding). Association does not imply causation, due to the fact that association doesn't have a direction (e.g. a rooster's crow is associated with the sun rising, but is not the cause of it), and due to the possibility of confounding variables that have an effect on both treatment and outcome variables (e.g. eating ice cream is probably associated with drowning, since going to the beach increases the probability of both ice cream consumption and drowning). One might be tempted (many researchers have been) to simply control for as many covariates as possible in order to reduce the probability of significant confounding. However, the section about colliders will explain why this can be a bad strategy.\n",
    "\n",
    "## Graphical Causal Model (DAG)\n",
    "\n",
    "Graphical models can be utilized to visualize causal relationships between variables. Commonly used are DAGs, where each node represents a variable and each edge a causal relationship. An edge from $A$ to $B$ means that $A$ is a cause of $B$. You can read more about causal graphs in chapters 3 and 4 of the [Introduction to Causal Inference](https://www.bradyneal.com/causal-inference-course)-book. The simple DAG below (copied from the book) has a common structure, where treatment $T$ is a cause of outcome $Y$, and confounder $W$ is a common cause of both $T$ and $Y$. We are usually interested in the causal effect of the treatment on the outcome.\n",
    "\n",
    "![figures/dag_1.png](figures/dag_1.png)\n",
    "\n",
    "## Structural Causal Model (SCM)\n",
    "\n",
    "Graphical causal models are very useful, but SCMs can bring additional clarity and allow us to compute counterfactuals. You can read about SCMs in section 4.5 of the [Introduction to Causal Inference](https://www.bradyneal.com/causal-inference-course)-book, where they are defined as:\n",
    "\n",
    "> A structural causal model is a tuple of the following sets:\n",
    "> 1. A set of endogenous variables $V$\n",
    "> 2. A set of exogenous variables $U$\n",
    "> 3. A set of functions $f$, one to generate each endogenous variable as a function of other variables\n",
    "\n",
    "Endogenous variables are variables with parents in the corresponding causal graph, i.e. the variables we are modeling the cause(s) of. Exogenous variables are the variables without parents in the causal graph. An example from the book are the following *structural equations*\n",
    "\n",
    "![figures/scm_example.png](figures/scm_example.png)\n",
    "\n",
    "that correspond to the following DAG\n",
    "\n",
    "![figures/scm_example_dag.png](figures/scm_example_dag.png)\n",
    "\n",
    "Here the endogenous variables are ${B,C,D}$ and the exogenous variables are ${A,U_B,U_C,U_D}$. The set ${U_B,U_C,U_D}$ are noise variables that make the endogenous variables random variables even if all functions in $f$ are deterministic (noise variables are usually ommited from DAGs).\n",
    "\n",
    "TODO!!!! Show SCM used for data generating process below\n",
    "\n",
    "## Data generating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_w():\n",
    "    u_w = np.random.choice([0, 1])\n",
    "    return u_w\n",
    "\n",
    "def f_t(w):\n",
    "    u_t = np.random.normal()\n",
    "    intermediate = 0.5 * w + u_t\n",
    "    return 1 if intermediate > 0 else 0\n",
    "\n",
    "def f_y(w, t):\n",
    "    u_y = np.random.normal()\n",
    "    return 0.8 * w + 1.2 * t + u_y\n",
    "\n",
    "W = np.array([f_w() for _ in range(NUM_DATA_POINTS)])\n",
    "T = np.array([f_t(w) for w in W])\n",
    "Y = np.array([f_y(w, t) for w, t in zip(W, T)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO: Show that association is not caussal effect here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification\n",
    "\n",
    "Backdoor criterion\n",
    "\n",
    "Backdoor adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation\n",
    "\n",
    "Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE estimate: 1.2012474981998513\n"
     ]
    }
   ],
   "source": [
    "WT = np.array([W, T]).T\n",
    "WT_1 = np.array([W, np.ones(len(W))]).T\n",
    "WT_0 = np.array([W, np.zeros(len(W))]).T\n",
    "model = LinearRegression()\n",
    "model.fit(WT, Y)\n",
    "ate_estimate = np.mean(model.predict(WT_1) - model.predict(WT_0))\n",
    "print(\"ATE estimate:\", ate_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE estimate: 1.2012474981998507\n"
     ]
    }
   ],
   "source": [
    "print(\"ATE estimate:\", model.coef_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colliders\n",
    "\n",
    "![figures/dag_2.png](figures/dag_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_w():\n",
    "    u_w = np.random.choice([0, 1])\n",
    "    return u_w\n",
    "\n",
    "def f_t(w):\n",
    "    u_t = np.random.normal()\n",
    "    intermediate = 0.5 * w + u_t\n",
    "    return 1 if intermediate > 0 else 0\n",
    "\n",
    "def f_y(w, t):\n",
    "    u_y = np.random.normal()\n",
    "    return 0.8 * w + 1.2 * t + u_y\n",
    "\n",
    "def f_z(t, y):\n",
    "    u_z = np.random.normal()\n",
    "    intermediate = 1.5 * t + y - 2 + u_z\n",
    "    return 1 if intermediate > 0 else 0\n",
    "\n",
    "W = np.array([f_w() for _ in range(NUM_DATA_POINTS)])\n",
    "T = np.array([f_t(w) for w in W])\n",
    "Y = np.array([f_y(w, t) for w, t in zip(W, T)])\n",
    "Z = np.array([f_z(t, y) for t, y in zip(T, Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE estimate: 0.40757848747942743\n"
     ]
    }
   ],
   "source": [
    "WZT = np.array([W, Z, T]).T\n",
    "WZT_1 = np.array([W, Z, np.ones(len(W))]).T\n",
    "WZT_0 = np.array([W, Z, np.zeros(len(W))]).T\n",
    "model = LinearRegression()\n",
    "model.fit(WZT, Y)\n",
    "ate_estimate = np.mean(model.predict(WZT_1) - model.predict(WZT_0))\n",
    "print(\"ATE estimate:\", ate_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE estimate: 1.196696813274864\n"
     ]
    }
   ],
   "source": [
    "WT = np.array([W, T]).T\n",
    "WT_1 = np.array([W, np.ones(len(W))]).T\n",
    "WT_0 = np.array([W, np.zeros(len(W))]).T\n",
    "model = LinearRegression()\n",
    "model.fit(WT, Y)\n",
    "ate_estimate = np.mean(model.predict(WT_1) - model.predict(WT_0))\n",
    "print(\"ATE estimate:\", ate_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unobserved confounding\n",
    "\n",
    "![figures/dag_3.png](figures/dag_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_w():\n",
    "    u_w = np.random.choice([0, 1])\n",
    "    return u_w\n",
    "\n",
    "def f_u():\n",
    "    u_u = np.random.normal()\n",
    "    return u_u\n",
    "\n",
    "def f_t(w, u):\n",
    "    u_t = np.random.normal()\n",
    "    intermediate = 0.5 * w + 0.8 * u + u_t\n",
    "    return 1 if intermediate > 0 else 0\n",
    "\n",
    "def f_y(w, u, t):\n",
    "    u_y = np.random.normal()\n",
    "    return 0.8 * w - 2 * u + 1.2 * t + u_y\n",
    "\n",
    "W = np.array([f_w() for _ in range(NUM_DATA_POINTS)])\n",
    "U = np.array([f_u() for _ in range(NUM_DATA_POINTS)])\n",
    "T = np.array([f_t(w, u) for w, u in zip(W, U)])\n",
    "Y = np.array([f_y(w, u, t) for w, u, t in zip(W, U, T)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE estimate: -0.8108111630460578\n"
     ]
    }
   ],
   "source": [
    "WT = np.array([W, T]).T\n",
    "WT_1 = np.array([W, np.ones(len(W))]).T\n",
    "WT_0 = np.array([W, np.zeros(len(W))]).T\n",
    "model = LinearRegression()\n",
    "model.fit(WT, Y)\n",
    "ate_estimate = np.mean(model.predict(WT_1) - model.predict(WT_0))\n",
    "print(\"ATE estimate:\", ate_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "TODO\n",
    "\n",
    "Just a small part of causal inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-inference-playground-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
